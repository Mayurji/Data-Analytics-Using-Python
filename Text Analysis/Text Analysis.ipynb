{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='D:/textAnalysis/austen-emma-excerpt.txt' mode='r' encoding='cp1252'>\n",
      "78\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "infile = open('D:/textAnalysis/austen-emma-excerpt.txt')\n",
    "print(infile)\n",
    "text = infile.read()\n",
    "print(text.count(\"e\"))\n",
    "print(text.count('an'))\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Emma by Jane Austen 1816\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "nE = 0\n",
    "print(text)\n",
    "for x in text:\n",
    "    if 'e' in x:\n",
    "        nE = nE + x.count('e')\n",
    "\n",
    "print(nE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(text.count(' an '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "counts = 0 \n",
    "item_to_count = text\n",
    "for txt in text:\n",
    "    if 'e' == txt:\n",
    "        counts = counts + 1\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punc2(text):\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>>,.?/~`»¿'\n",
    "    clean_text = \"\"\n",
    "    for character in text:\n",
    "        if character not in punctuation:\n",
    "            clean_text += character\n",
    "    return clean_text\n",
    "\n",
    "#short_text = \"Commas, as it turns out, are overestimated. Dots, however, even more so!\"\n",
    "#words = remove_punc2(text)\n",
    "#count = {}\n",
    "#textSplit = words.split(' ')\n",
    "#for x in textSplit:\n",
    "#        if x in text:\n",
    "#            count[x] = count[x] + 1\n",
    "#        else:\n",
    "#            count[x] = 1\n",
    "        #print('The word '+ x +' occurred ' +str(wordCount))\n",
    "#print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'P')\n",
      "(1, 'y')\n",
      "(2, 't')\n",
      "(3, 'h')\n",
      "(4, 'o')\n",
      "(5, 'n')\n"
     ]
    }
   ],
   "source": [
    "for element in enumerate(\"Python\"):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for index, character in enumerate(\"Python\"):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿ Emma by Jane Austen 1816\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "D:/textAnalysis/austen-emma-excerpt.txt has 704 characters.\n",
      "D:/textAnalysis/austen-emma.txt has 0 characters.\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    infile = open(filename) # windows users should use codecs.open after importing codecs\n",
    "    contents = infile.read()\n",
    "    infile.close()\n",
    "    return contents\n",
    "\n",
    "fileContent = read_file(\"D:/textAnalysis/austen-emma-excerpt.txt\")\n",
    "print(fileContent)\n",
    "\n",
    "from os import listdir\n",
    "listdir(\"D:/textAnalysis\")\n",
    "\n",
    "def list_textfiles(directory):\n",
    "    \"Return a list of filenames ending in '.txt' in DIRECTORY.\"\n",
    "    textfiles = []\n",
    "    for filename in listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            textfiles.append(directory + \"/\" + filename)\n",
    "    return textfiles\n",
    "\n",
    "for filepath in list_textfiles(\"D:/textAnalysis\"):\n",
    "    text = read_file(filepath)\n",
    "    print(filepath +  \" has \" + str(len(text)) + \" characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def end_of_sentence_marker(character):\n",
    "    if character == '?':\n",
    "        return True\n",
    "    elif character == '!':\n",
    "        return True\n",
    "    elif character == '.':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(end_of_sentence_marker('?') == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(end_of_sentence_marker(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'P')\n",
      "(1, 'y')\n",
      "(2, 't')\n",
      "(3, 'h')\n",
      "(4, 'o')\n",
      "(5, 'n')\n"
     ]
    }
   ],
   "source": [
    "for element in enumerate('Python'):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for index, character in enumerate(\"Python\"):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    #\"Split a text string into a list of sentences.\"\n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for end, character in enumerate(text):\n",
    "        if end_of_sentence_marker(character):\n",
    "            sentence = text[start: end + 1]\n",
    "            sentences.append(sentence)\n",
    "            start = end + 1\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splitedSentences = split_sentences(\"This is a sentence. Should we seperate it from this one?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'sentence']]\n",
      "[['should', 'we', 'seperate', 'it', 'from', 'this', 'one']]\n"
     ]
    }
   ],
   "source": [
    "for index,sent in enumerate(splitedSentences):\n",
    "    wordList = []\n",
    "    sent = sent.strip()\n",
    "    cleanText = remove_punc2(sent)\n",
    "    lowerSent = cleanText.lower()\n",
    "    wordList = lowerSent.split(' ')\n",
    "    print(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To Remove extension of a file , we can use \"os.path.splitext\" !\n",
    "# To Remove directory and gives only the file name , we can use \"os.path.basename\" !\n",
    "# Using the above two function we can get only the required file name !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@Fox', '@Judie'), ('@Tristan', '@Jermain'), ('@Allyn', '@Winfred'), ('@Dennis', '@Randolph'), ('@Wallie', '@Venkat'), ('@Fo', '@Judi'), ('@Trista', '@Jermai'), ('@lyn', '@Winfre'), ('@ennis', '@Randolp'), ('@llie', '@Venka')]\n"
     ]
    }
   ],
   "source": [
    "edges = [] # In twitterName.txt we have list of names in the format as 'follower','followee'\n",
    "for line in open('D:/textAnalysis/twitterName.txt'):\n",
    "    follower,followee = line.strip().split(';')\n",
    "    edges.append((follower,followee))\n",
    "print(edges[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@Judie', '@Judie', '@Jermain', '@Winfred', '@Randolph', '@Venkat']\n"
     ]
    }
   ],
   "source": [
    "def following(user, edges):\n",
    "    \"Return a list of all users USERS is following.\"\n",
    "    followees = []\n",
    "    for follower, followee in edges:\n",
    "        if follower == user:\n",
    "            followees.append(followee)\n",
    "    return followees\n",
    "\n",
    "print(following(\"@Fox\", edges)) # The User Fox(follower) is following 6 People(Followee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 11.93 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 2.03 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit following(\"@Fox\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edge_dict = {}\n",
    "for line in open(\"D:/textAnalysis/twitterName.txt\"):\n",
    "    name_a, name_b = line.strip().split(';')\n",
    "    if name_a in edge_dict:\n",
    "        edge_dict[name_a].append(name_b)\n",
    "    else:\n",
    "        edge_dict[name_a] = [name_b] # We are writing to an Dictionary 'key' as Follower and 'Value as Follower' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@Alln': ['@nfred'],\n",
       " '@Allyn': ['@Winfred'],\n",
       " '@Dennis': ['@Randolph'],\n",
       " '@Denns': ['@ndolph'],\n",
       " '@Fo': ['@Judi'],\n",
       " '@Fox': ['@Judie', '@Judie', '@Jermain', '@Winfred', '@Randolph', '@Venkat'],\n",
       " '@Fx': ['@Jie'],\n",
       " '@Trista': ['@Jermai'],\n",
       " '@Tristan': ['@Jermain'],\n",
       " '@Trstan': ['@rmain'],\n",
       " '@Walli': ['@enkat'],\n",
       " '@Wallie': ['@Venkat'],\n",
       " '@allie': ['@nkat'],\n",
       " '@ennis': ['@Randolp', '@Raolph'],\n",
       " '@llie': ['@Venka'],\n",
       " '@llyn': ['@Winfr'],\n",
       " '@lyn': ['@Winfre'],\n",
       " '@ox': ['@Jud'],\n",
       " '@ristan': ['@Jerma']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.85 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 238 ns per loop\n"
     ]
    }
   ],
   "source": [
    "def following2(user, edges):\n",
    "    return edges[user]\n",
    "\n",
    "%timeit following2(\"@Fox\", edge_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edges = []\n",
    "for line in open(\"D:/textAnalysis/twitterName.txt\"):\n",
    "    name_a, name_b = line.strip().split(';')\n",
    "    # repeatedly add edges to the network (1000 times)\n",
    "    for i in range(1000):\n",
    "        edges.append((name_a, name_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 71.55 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 2.91 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit following(\"@Fox\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.09 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 176 ns per loop\n"
     ]
    }
   ],
   "source": [
    "edge_dict = {}\n",
    "for line in open(\"D:/textAnalysis/twitterName.txt\"):\n",
    "    name_a, name_b = line.strip().split(';')\n",
    "    for i in range(1000):\n",
    "        if name_a in edge_dict:\n",
    "            edge_dict[name_a].append(name_b)\n",
    "        else:\n",
    "            edge_dict[name_a] = [name_b]\n",
    "\n",
    "%timeit following2(\"@Fox\", edge_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acticePray'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# English to Latin\n",
    "# On First occurance of an vowel the loop breaks\n",
    "def translate(word):\n",
    "    \"Convert a word to latin.\"\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    start = 0\n",
    "    end = ''\n",
    "    # loop over all characters in word\n",
    "    for i, char in enumerate(word):\n",
    "        # if this character is not a vowel\n",
    "        if char not in vowels:\n",
    "            # it is a consonant, so add it to the end.\n",
    "            end += char\n",
    "        # if it is a vowel\n",
    "        else:\n",
    "            # we set the starting position to \n",
    "            # the position of this character\n",
    "            start = i\n",
    "            break\n",
    "    return word[start:] + end + 'ay'\n",
    "\n",
    "translate('Practice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method 1\n",
    "def starts_with_vowel(strings):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    if strings[0] in vowels:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "starts_with_vowel('Amazing')\n",
    "starts_with_vowel('Jack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method 2\n",
    "def starts_with_vowel(word):\n",
    "    \"Return True if WORD starts with a vowel, False otherwise.\"\n",
    "    vowels = ('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U')\n",
    "    return word.startswith(vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'luckily'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_suffix(word,suffix):\n",
    "    word_suffix = word + suffix\n",
    "    return word_suffix\n",
    "\n",
    "add_suffix('luck','ily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quickly'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'quick' \n",
    "add_suffix(word,'ly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EEEEJkcAmazing'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(word, suffix):\n",
    "    if starts_with_vowel(word):\n",
    "        return add_suffix(word, suffix)\n",
    "    return translate(word[1:] + word[0], suffix)\n",
    "\n",
    "translate('JkcEEEE','Amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
